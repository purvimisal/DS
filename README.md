
# Data Science Projects

### These are some of the data science projects I have worked on assembled in one repository. The details are listed below: 

* ### [Absenteeism](https://github.com/purvimisal/datascience/tree/master/Absenteeism)
    This project analyses and predicts the absenteeism of employees in a corporation. Absenteeism is defined as a habitual pattern of absence from a duty or obligation without good reason. Different preprocessing techniques are applied and prediction is implemented using logistic regression. 
    
* ### [Audiobooks customer retention prediction](https://github.com/purvimisal/datascience/tree/master/Audiobooks_customer_retention_prediction)
    This project analyses and predicts customer rentention for audiobooks. Different preprocessing techniques like balancing the dataset, standardization, and shuffling are applied. A sequential model with three layers is created with an early stopping mechanism using tf.keras library to train on the dataset and make predictions.  
    
* ### [Bank churn prediction](https://github.com/purvimisal/datascience/tree/master/Bank-churn-prediction)
    This project uses an artificial neural network with three layers to predict Bank churn prediction with an unbalanced dataset first and then a balanced dataset with early stopping mechanism, and compares the two results.  
    
* ### [Customer Behavior Analysis and Prediction](https://github.com/purvimisal/datascience/tree/master/Customer-Behavior-Analysis-and-Prediction)
    The objective of this project is to answer the question of how the transaction history of customers/consumers can give insight into consumersâ€™ purchasing habits and also predict the products consumers might be interested in buying in the future. This kind of information can be used to align business decisions and also to understand which consumers are most valuable to the retail store, along with other essential insights.  

* ### [HCC survival prediction](https://github.com/purvimisal/datascience/tree/master/HCC-survival-prediction)  
    This project predicts the survival rate of patients with Hepatocellular carcinoma. Preprocessing steps involve handling missing and nulls values using different methods. For prediction of survival which is a classification problem, Support Vector Classifier and Logistic Regression is used and their results are compared. GridSearchCV is used to compute the best parameters for SVC model.  
    
* ### [SMS Spam Classification](https://github.com/purvimisal/datascience/tree/master/SMS-Spam-Classification-Naive-Bayes) 
    This project performs classification of SMSs' into spam or ham (binary classification) using Multinomial Naive Bayes algorithm. Preprocessing techniques like randomization of data, and cleaning the messages of unnecessary characters is done. After which the conditional probabilities of words are calculated to classify them into one of the two categories. 
    
* ### [Topic Modeling on NPR data](https://github.com/purvimisal/datascience/tree/master/Topic-Modelling-NPR)
    This project uses two techniques to classify articles from NPR (National Public Radio) into different topics:
    1. __Latent Dirichlet Allocation__: LDA is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.
    1. __Non-Negative Matric Factorization__: NMF or NNMF is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements.
    

* ### [Toxic Comment Classification](https://github.com/purvimisal/datascience/tree/master/Toxic-comment-classification)
    *Kaggle's Toxic Comment Classification Competition*  
    This project predicts how toxic a comment is and classifies into one of these categories: ['obscene','insult','toxic','severe_toxic','identity_hate','threat']. The preprocessing techniques involve cleaning the data/comments, removing stop words, performing lemmatization, and then TF-IDF vectorization of the terms. 
