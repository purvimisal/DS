{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam filter using Naive Bayes from scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sms_data = pd.read_csv('smsspamcollection/SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "sms_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before splitting dataset into training and testing dataset, \n",
    "# I will be shuffling the dataset and randomizing it to split training and test dataset \n",
    "#with balanced labels (having same ham:spam in test dataset and train dataset both)\n",
    "\n",
    "# Splitting with 70% training and 30% test dataset\n",
    "\n",
    "# randomizing  dataset\n",
    "randomized_data = sms_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# calculating the index for splitting\n",
    "index = round(len(randomized_data) * 0.7)\n",
    "\n",
    "# splitting into training and test datasets\n",
    "train_data = randomized_data[:index].reset_index(drop=True)\n",
    "test_data = randomized_data[index:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 2)\n",
      "(1672, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865897\n",
       "spam    0.134103\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866029\n",
       "spam    0.133971\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning is required as all words need to be extracted separately. \n",
    "#Words in the SMS are the features \n",
    "\n",
    "#Removing punctuations \n",
    "train_data['SMS'] = train_data['SMS'].str.replace('\\W', ' ')\n",
    "\n",
    "# all words to lower\n",
    "train_data['SMS'] = train_data['SMS'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bag of words/ vocabulary from words in SMS \n",
    "\n",
    "train_data['SMS'] = train_data['SMS'].str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for sms in train_data['SMS']:\n",
    "    for w in sms:\n",
    "#         print(w)\n",
    "        vocab.append(w)\n",
    "\n",
    "vocab = list(set(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7212"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['true',\n",
       " '0870753331018',\n",
       " 'priority',\n",
       " 'nokia',\n",
       " 'xy',\n",
       " '89693',\n",
       " 'bid',\n",
       " '300',\n",
       " 'lover',\n",
       " 'rcd',\n",
       " 'body',\n",
       " 'urination',\n",
       " 'land',\n",
       " '88600',\n",
       " 'prayers',\n",
       " 'tough',\n",
       " 'hoped',\n",
       " 'nasty',\n",
       " '25p',\n",
       " 'u2moro',\n",
       " 'power',\n",
       " 'prospects',\n",
       " 'remembr',\n",
       " 'promise',\n",
       " 'scary',\n",
       " 'sweets',\n",
       " 'edison',\n",
       " 'mayb',\n",
       " 'busy',\n",
       " 'speechless',\n",
       " 'charlie',\n",
       " '24m',\n",
       " 'totes',\n",
       " 'burrito',\n",
       " 'banks',\n",
       " 'whispers',\n",
       " 'youre',\n",
       " 'reacting',\n",
       " 'geeee',\n",
       " 'student',\n",
       " 'velly',\n",
       " 'uv',\n",
       " 'plaid',\n",
       " '87021',\n",
       " 'thread',\n",
       " '42810',\n",
       " 'childrens',\n",
       " 'meive',\n",
       " 'area',\n",
       " '946',\n",
       " 'monkey',\n",
       " 'themob',\n",
       " 'reverse',\n",
       " 'dined',\n",
       " 'cheese',\n",
       " 'strongly',\n",
       " 'science',\n",
       " 'sh',\n",
       " 'hundred',\n",
       " 'wants',\n",
       " 'beerage',\n",
       " '08718726270',\n",
       " 'cardiff',\n",
       " 'uawake',\n",
       " 'meal',\n",
       " 'breathe1',\n",
       " 'suzy',\n",
       " 'pale',\n",
       " 'patrick',\n",
       " '07973788240',\n",
       " 'infernal',\n",
       " 'email',\n",
       " 'raed',\n",
       " 'filthyguys',\n",
       " 'eighth',\n",
       " 'complacent',\n",
       " 'sack',\n",
       " 'butt',\n",
       " 'got',\n",
       " 'wahala',\n",
       " 'fooled',\n",
       " 'hour',\n",
       " 'local',\n",
       " 'realised',\n",
       " 'yaxx',\n",
       " 'landline',\n",
       " 'prey',\n",
       " 'toll',\n",
       " 'appy',\n",
       " 'soryda',\n",
       " 'role',\n",
       " 'helping',\n",
       " '20',\n",
       " 'lunchtime',\n",
       " 'spoke',\n",
       " 'eveb',\n",
       " 'somebody',\n",
       " 'bowl',\n",
       " 'sexy',\n",
       " 'happens',\n",
       " 'surely',\n",
       " 'flights',\n",
       " 'fucking',\n",
       " 'yep',\n",
       " 'or2optout',\n",
       " 'x49',\n",
       " '20p',\n",
       " '8077',\n",
       " 'perumbavoor',\n",
       " 'camcorder',\n",
       " '12hrs',\n",
       " 'noun',\n",
       " 'hey',\n",
       " 'sabarish',\n",
       " 'downs',\n",
       " 'westlife',\n",
       " '087187272008',\n",
       " '9ja',\n",
       " 'gep',\n",
       " 'textbuddy',\n",
       " 'yuou',\n",
       " '09064015307',\n",
       " 'secs',\n",
       " 'bathroom',\n",
       " 'gardener',\n",
       " '447797706009',\n",
       " 'seeking',\n",
       " 'haiz',\n",
       " '6',\n",
       " 'lanka',\n",
       " 'waste',\n",
       " 'cutefrnd',\n",
       " '89555',\n",
       " '09050001808',\n",
       " 'squeezed',\n",
       " 'holiday',\n",
       " '69988',\n",
       " 'quit',\n",
       " 'dnt',\n",
       " 'toxic',\n",
       " 'brand',\n",
       " 'epi',\n",
       " 'kiefer',\n",
       " 'owo',\n",
       " 'matra',\n",
       " '140',\n",
       " 'gettin',\n",
       " 'csc',\n",
       " 'fool',\n",
       " 'gently',\n",
       " '153',\n",
       " 'watches',\n",
       " 'beendropping',\n",
       " 'alert',\n",
       " 'moments',\n",
       " 'ym',\n",
       " 'postcard',\n",
       " 'vco',\n",
       " 'www',\n",
       " 'coco',\n",
       " 'traveling',\n",
       " '08002986030',\n",
       " '40533',\n",
       " 'late',\n",
       " 'continue',\n",
       " 'thinkthis',\n",
       " 'outstanding',\n",
       " 'error',\n",
       " 'cthen',\n",
       " 'w1jhl',\n",
       " 'sure',\n",
       " 'step',\n",
       " 'nattil',\n",
       " 'mobs',\n",
       " 'cover',\n",
       " 'gam',\n",
       " 'nan',\n",
       " 'wanting',\n",
       " 'den',\n",
       " 'center',\n",
       " 'u',\n",
       " 'antelope',\n",
       " 'co',\n",
       " 'traditions',\n",
       " 'noe',\n",
       " 'je',\n",
       " 'fromwrk',\n",
       " 'department',\n",
       " 'yoville',\n",
       " '09061213237',\n",
       " 'billion',\n",
       " 'combination',\n",
       " 'checkin',\n",
       " 'classic',\n",
       " 'chk',\n",
       " 'beforehand',\n",
       " 'age',\n",
       " 'instantly',\n",
       " 'txting',\n",
       " 'teams',\n",
       " 'restocked',\n",
       " 'events',\n",
       " 'textin',\n",
       " 'uncle',\n",
       " 'fatty',\n",
       " 'thts',\n",
       " 'kr',\n",
       " 'aids',\n",
       " 'pierre',\n",
       " 'invite',\n",
       " 'dual',\n",
       " 'prepare',\n",
       " 'anyplaces',\n",
       " 'patent',\n",
       " 'dungerees',\n",
       " 'nottingham',\n",
       " 'end',\n",
       " 'funky',\n",
       " 'jesus',\n",
       " 'colourful',\n",
       " 'com',\n",
       " 'great',\n",
       " 'jane',\n",
       " 'delivered',\n",
       " 'see',\n",
       " 'gap',\n",
       " 'huh',\n",
       " 'jenny',\n",
       " 'pleasant',\n",
       " 'host',\n",
       " 'telephonic',\n",
       " 'hahaha',\n",
       " '3rd',\n",
       " 'reminder',\n",
       " 'ne',\n",
       " 'blackberry',\n",
       " 'air1',\n",
       " 'done',\n",
       " 'grownup',\n",
       " 'silence',\n",
       " 'chances',\n",
       " 'combine',\n",
       " 'lily',\n",
       " 'orchard',\n",
       " 'karaoke',\n",
       " 'discuss',\n",
       " 'market',\n",
       " 'lock',\n",
       " 'percentages',\n",
       " 'bids',\n",
       " 'leh',\n",
       " 'signin',\n",
       " 'unusual',\n",
       " 'ago',\n",
       " '872',\n",
       " 'rcvd',\n",
       " 'dorm',\n",
       " 'often',\n",
       " 'faith',\n",
       " 'lou',\n",
       " 'quizzes',\n",
       " 'gr8',\n",
       " 'buzz',\n",
       " 'train',\n",
       " 'conveying',\n",
       " 'exchanged',\n",
       " 'detroit',\n",
       " 'lose',\n",
       " 'applying',\n",
       " 'impede',\n",
       " 'wating',\n",
       " 'trainners',\n",
       " 'headstart',\n",
       " 'take',\n",
       " 'loans',\n",
       " 'nmde',\n",
       " 'click',\n",
       " 'toplay',\n",
       " 'jeetey',\n",
       " 'bcoz',\n",
       " 'executive',\n",
       " 'pix',\n",
       " 'behalf',\n",
       " 'neither',\n",
       " 'valid12hrs',\n",
       " 'acc',\n",
       " 'happen',\n",
       " 'using',\n",
       " '3100',\n",
       " 'comb',\n",
       " 'hesitate',\n",
       " 'isaiah',\n",
       " 'hard',\n",
       " 'firsg',\n",
       " '08712460324',\n",
       " 'novelty',\n",
       " 'search',\n",
       " 'stay',\n",
       " 'now1',\n",
       " 'vilikkam',\n",
       " 'roomate',\n",
       " 'face',\n",
       " 'carly',\n",
       " 'overtime',\n",
       " 'oz',\n",
       " 'enemies',\n",
       " 'stressfull',\n",
       " 'sale',\n",
       " 'theory',\n",
       " '29',\n",
       " 'pose',\n",
       " 'africa',\n",
       " '80',\n",
       " 'shouldn',\n",
       " '24hrs',\n",
       " 'team',\n",
       " 'speeding',\n",
       " 'receivea',\n",
       " 'sup',\n",
       " 'amy',\n",
       " 'dobby',\n",
       " 'younger',\n",
       " '30pm',\n",
       " 'mj',\n",
       " 'folks',\n",
       " 'choosing',\n",
       " 'dining',\n",
       " 'happily',\n",
       " 'or2stoptxt',\n",
       " 'gumby',\n",
       " 'commercial',\n",
       " 'waliking',\n",
       " 'ger',\n",
       " 'library',\n",
       " 'creative',\n",
       " 'envelope',\n",
       " 'innocent',\n",
       " 'weirdest',\n",
       " 'swan',\n",
       " 'whenever',\n",
       " 'gbp5',\n",
       " 'mis',\n",
       " 'chinnu',\n",
       " 'tues',\n",
       " 'resent',\n",
       " 'rally',\n",
       " 'shsex',\n",
       " 'stdtxtrate',\n",
       " 'cliffs',\n",
       " 'april',\n",
       " 'jetton',\n",
       " 'hits',\n",
       " 'collapsed',\n",
       " 'including',\n",
       " 'removed',\n",
       " 'said',\n",
       " 'gave',\n",
       " 'pass',\n",
       " 'mufti',\n",
       " 'soon',\n",
       " 'beggar',\n",
       " 'future',\n",
       " 'mental',\n",
       " '9t',\n",
       " 'mood',\n",
       " 'pendent',\n",
       " 'fainting',\n",
       " 'sacrifice',\n",
       " 'weeks',\n",
       " 'mah',\n",
       " 'kind',\n",
       " 'receipt',\n",
       " 'befor',\n",
       " 'become',\n",
       " 'drum',\n",
       " 'staying',\n",
       " 'professional',\n",
       " 'rounder',\n",
       " 'jd',\n",
       " 'promotion',\n",
       " 'christ',\n",
       " 'spain',\n",
       " 'gas',\n",
       " 'inde',\n",
       " 'olayiwola',\n",
       " 'track',\n",
       " '08452810075over18',\n",
       " 'kindly',\n",
       " '08714712412',\n",
       " 'meaning',\n",
       " 'move',\n",
       " 'lovejen',\n",
       " 'shall',\n",
       " 'neglet',\n",
       " 'soil',\n",
       " '89123',\n",
       " 'moral',\n",
       " 'could',\n",
       " '09111030116',\n",
       " '434',\n",
       " '09099726481',\n",
       " 'heal',\n",
       " 'darkest',\n",
       " 'petrol',\n",
       " 'satanic',\n",
       " 'eta',\n",
       " 'hunks',\n",
       " 'about',\n",
       " 'cannot',\n",
       " 'thanx',\n",
       " 't4get2text',\n",
       " 'sochte',\n",
       " '1win150ppmx3',\n",
       " 'called',\n",
       " 'gram',\n",
       " 'ah',\n",
       " '3gbp',\n",
       " 'hug',\n",
       " 'arent',\n",
       " 'howdy',\n",
       " 'munsters',\n",
       " 'respond',\n",
       " 'hairdressers',\n",
       " 'icicibank',\n",
       " 'placement',\n",
       " 'mrt',\n",
       " 'restrict',\n",
       " 'ts',\n",
       " '08712402902',\n",
       " 'outages',\n",
       " 'group',\n",
       " 'padhe',\n",
       " 'tim',\n",
       " '4ward',\n",
       " 'fireplace',\n",
       " '0quit',\n",
       " 'ugadi',\n",
       " 'pmt',\n",
       " 'tones2you',\n",
       " 'bites',\n",
       " 'hitter',\n",
       " 'evenings',\n",
       " 'buzy',\n",
       " 'willpower',\n",
       " 'springs',\n",
       " 'bread',\n",
       " '2watershd',\n",
       " 'ecstacy',\n",
       " 'tming',\n",
       " 'fringe',\n",
       " 'dead',\n",
       " 'following',\n",
       " 'ip4',\n",
       " 'lions',\n",
       " 'shoot',\n",
       " 'eventually',\n",
       " 'house',\n",
       " 'budget',\n",
       " 'diet',\n",
       " 'renewing',\n",
       " 'asking',\n",
       " 'wesleys',\n",
       " 'nw',\n",
       " '83110',\n",
       " 'obviously',\n",
       " '85',\n",
       " 'dancin',\n",
       " 'swiss',\n",
       " 'finishes',\n",
       " 'sports',\n",
       " 'wahleykkum',\n",
       " 'suppose',\n",
       " 'gentleman',\n",
       " 'cafe',\n",
       " 'drunken',\n",
       " 'bahamas',\n",
       " 'sipix',\n",
       " '83049',\n",
       " '13',\n",
       " 'sd',\n",
       " '1stone',\n",
       " 'eldest',\n",
       " 'reslove',\n",
       " '900',\n",
       " 'ta',\n",
       " 'sankranti',\n",
       " 'nimya',\n",
       " 'cc100p',\n",
       " 'wined',\n",
       " 'satisfied',\n",
       " 'wise',\n",
       " 'how',\n",
       " 'fond',\n",
       " '2morro',\n",
       " 'please',\n",
       " 'enough',\n",
       " 'prepayment',\n",
       " 'buzzzz',\n",
       " 'ibiza',\n",
       " 'mtmsg18',\n",
       " 'usc',\n",
       " 'lousy',\n",
       " 'squishy',\n",
       " 'curfew',\n",
       " 'scarcasim',\n",
       " 'tightly',\n",
       " 'savamob',\n",
       " 'register',\n",
       " 'class',\n",
       " 'cared',\n",
       " 'ctla',\n",
       " 'negative',\n",
       " 'interested',\n",
       " 'randomlly',\n",
       " '5th',\n",
       " 'unconscious',\n",
       " 'per',\n",
       " 'lv',\n",
       " 'boyfriend',\n",
       " 'max6',\n",
       " 'requests',\n",
       " 'é',\n",
       " '2waxsto',\n",
       " '447801259231',\n",
       " 'ph',\n",
       " 'particularly',\n",
       " 'onbus',\n",
       " 'heltini',\n",
       " 'unbreakable',\n",
       " 'frnds',\n",
       " 'thanks2',\n",
       " 'tayseer',\n",
       " 'urmom',\n",
       " '3xx',\n",
       " 'g',\n",
       " 'vip',\n",
       " 'upd8',\n",
       " 'drove',\n",
       " 'andre',\n",
       " 'strong',\n",
       " '07090298926',\n",
       " 'provided',\n",
       " 'coughing',\n",
       " 'matrix3',\n",
       " 'shouted',\n",
       " 'less',\n",
       " 'infections',\n",
       " 'moved',\n",
       " 'daddy',\n",
       " 'bone',\n",
       " 'diapers',\n",
       " 'honeybee',\n",
       " 'okay',\n",
       " 'shu',\n",
       " 'ma',\n",
       " 'evrydy',\n",
       " 'drms',\n",
       " 'wil',\n",
       " 'pillows',\n",
       " 'head',\n",
       " 'rcb',\n",
       " 'attend',\n",
       " 'cornwall',\n",
       " 'java',\n",
       " 'police',\n",
       " 'clubzed',\n",
       " 'appreciate',\n",
       " '4years',\n",
       " 'priscilla',\n",
       " 'maximum',\n",
       " 'papa',\n",
       " 'swayze',\n",
       " 'trying',\n",
       " 'data',\n",
       " 'sex',\n",
       " 'mobno',\n",
       " '1hr',\n",
       " 'eatin',\n",
       " 'cm2',\n",
       " 'affair',\n",
       " 'tyler',\n",
       " 'excuse',\n",
       " 'normal',\n",
       " 'finest',\n",
       " 'verified',\n",
       " 'apart',\n",
       " 'calicut',\n",
       " 'mahaveer',\n",
       " 'content',\n",
       " 'tihs',\n",
       " 'images',\n",
       " 'training',\n",
       " 'meals',\n",
       " 'nosy',\n",
       " 'huiming',\n",
       " 'key',\n",
       " 'himself',\n",
       " 'subscribe',\n",
       " 'guesses',\n",
       " 'nokias',\n",
       " 'twittering',\n",
       " 'imma',\n",
       " 'dat',\n",
       " 'zindgi',\n",
       " 'toking',\n",
       " 'accenture',\n",
       " 'cust',\n",
       " 'txt43',\n",
       " 'alfie',\n",
       " 'aphex',\n",
       " 'omw',\n",
       " '08714714011',\n",
       " 'ahhhh',\n",
       " 'bbd',\n",
       " 'cousin',\n",
       " 'fondly',\n",
       " 'probs',\n",
       " 'jack',\n",
       " 'replacing',\n",
       " 'compulsory',\n",
       " 'tests',\n",
       " 'forwarding',\n",
       " 'reltnship',\n",
       " 'born',\n",
       " 'bother',\n",
       " 'necklace',\n",
       " 'method',\n",
       " 'lst',\n",
       " 'bishan',\n",
       " 'apps',\n",
       " 'messy',\n",
       " 'freshers',\n",
       " 'randomly',\n",
       " 'lands',\n",
       " 'upset',\n",
       " 'rocking',\n",
       " 'memory',\n",
       " 'jabo',\n",
       " 'subscription',\n",
       " 'roles',\n",
       " 'slide',\n",
       " 'ha',\n",
       " 'redeemable',\n",
       " 'died',\n",
       " 'yeh',\n",
       " 'babies',\n",
       " 'ave',\n",
       " 'liquor',\n",
       " 'appointments',\n",
       " 'bro',\n",
       " 'trip',\n",
       " 'edwards',\n",
       " '86688',\n",
       " 'aid',\n",
       " 'spiritual',\n",
       " 'side',\n",
       " 'been',\n",
       " 'mornings',\n",
       " 'cars',\n",
       " '09058095201',\n",
       " 'listening',\n",
       " 'depressed',\n",
       " 'speling',\n",
       " 'pan',\n",
       " 'inspection',\n",
       " 'lifpartnr',\n",
       " '40mph',\n",
       " 'whenevr',\n",
       " 'dorothy',\n",
       " 'drive',\n",
       " 'waiting',\n",
       " 'arab',\n",
       " 'traffic',\n",
       " '300603t',\n",
       " 'readiness',\n",
       " 'past',\n",
       " 'tlp',\n",
       " '150p16',\n",
       " 'goodmorning',\n",
       " 'january',\n",
       " 'remember',\n",
       " 'seriously',\n",
       " 'worc',\n",
       " 'prolly',\n",
       " 'honeymoon',\n",
       " 'unredeemed',\n",
       " 'vomit',\n",
       " 'snowball',\n",
       " 'tap',\n",
       " 'resubbing',\n",
       " 'but',\n",
       " '09061701461',\n",
       " 'deciding',\n",
       " 'meeting',\n",
       " '3mins',\n",
       " 'talent',\n",
       " 'password',\n",
       " '440',\n",
       " 'everyone',\n",
       " 'jolly',\n",
       " 'jokin',\n",
       " 'polyh',\n",
       " 'alle',\n",
       " 'poured',\n",
       " 'supports',\n",
       " 'como',\n",
       " 'reveal',\n",
       " 'token',\n",
       " 'skip',\n",
       " 'oncall',\n",
       " 'misss',\n",
       " 'lemme',\n",
       " 'poking',\n",
       " 'veggie',\n",
       " 'fiend',\n",
       " 'resolved',\n",
       " 'activities',\n",
       " 'polyc',\n",
       " 'forgotten',\n",
       " 'scenario',\n",
       " 'kadeem',\n",
       " 'ringtone',\n",
       " 'midnight',\n",
       " 'technologies',\n",
       " 'c',\n",
       " 'sk3',\n",
       " '500',\n",
       " 'sink',\n",
       " 'blowing',\n",
       " 'mint',\n",
       " '0808',\n",
       " 'full',\n",
       " 'grace',\n",
       " 'increments',\n",
       " 'nigpun',\n",
       " 'thing',\n",
       " 'abusers',\n",
       " 'share',\n",
       " 'copies',\n",
       " 'mmmmmmm',\n",
       " 'ad',\n",
       " 'oso',\n",
       " 'theoretically',\n",
       " 'dock',\n",
       " 'ho',\n",
       " 'somtimes',\n",
       " '23g',\n",
       " 'snappy',\n",
       " 'skyped',\n",
       " 'due',\n",
       " 'kip',\n",
       " '4041',\n",
       " 'rather',\n",
       " 'babygoodbye',\n",
       " 'leave',\n",
       " 'eye',\n",
       " 'senrd',\n",
       " 'covers',\n",
       " 'feb',\n",
       " 'wear',\n",
       " 'onion',\n",
       " 'keeps',\n",
       " 'don',\n",
       " 'affections',\n",
       " 'growing',\n",
       " '4a',\n",
       " 'solved',\n",
       " 'flute',\n",
       " 'ful',\n",
       " 'chicken',\n",
       " 'hogidhe',\n",
       " 'forced',\n",
       " 'sisters',\n",
       " 'theacusations',\n",
       " 'donate',\n",
       " 'sleep',\n",
       " 'lived',\n",
       " 'buttheres',\n",
       " 'cheaper',\n",
       " 'mathematics',\n",
       " 'casualty',\n",
       " 'empty',\n",
       " 'check',\n",
       " 'mm',\n",
       " 'emc1',\n",
       " 'oru',\n",
       " 'tolerat',\n",
       " 'table',\n",
       " 'send',\n",
       " 'yeovil',\n",
       " 'evry',\n",
       " 'm60',\n",
       " 'symptoms',\n",
       " 'selling',\n",
       " 'monkeespeople',\n",
       " 'regard',\n",
       " 'cheyyamo',\n",
       " 'fathima',\n",
       " 'inperialmusic',\n",
       " 'apes',\n",
       " 'woot',\n",
       " 'doubles',\n",
       " 'kothi',\n",
       " 'mail',\n",
       " 'aww',\n",
       " '80608',\n",
       " 'cttergg',\n",
       " 'dress',\n",
       " 'definitly',\n",
       " 'ashes',\n",
       " 'unsubscribe',\n",
       " 'ennal',\n",
       " 'spotty',\n",
       " 'victoria',\n",
       " 'tactless',\n",
       " 'nalla',\n",
       " 'videosounds',\n",
       " '85555',\n",
       " 'mrng',\n",
       " 'sunday',\n",
       " 'apo',\n",
       " 'netcollex',\n",
       " 'here',\n",
       " 'fights',\n",
       " '08718726978',\n",
       " '37819',\n",
       " 'prize',\n",
       " 'bite',\n",
       " '65',\n",
       " 'apply',\n",
       " 'if',\n",
       " 'pushes',\n",
       " 'girls',\n",
       " 'dvg',\n",
       " 'adam',\n",
       " 'nalli',\n",
       " 'dressed',\n",
       " 'from',\n",
       " 'mac',\n",
       " 'hospital',\n",
       " 'networking',\n",
       " 'claims',\n",
       " 'standing',\n",
       " 'footbl',\n",
       " 'argentina',\n",
       " 'catch',\n",
       " 'olave',\n",
       " 'useful',\n",
       " 'brandy',\n",
       " 'bfore',\n",
       " '5min',\n",
       " 'chinese',\n",
       " 'arnt',\n",
       " 'holder',\n",
       " 'shining',\n",
       " 'steal',\n",
       " 'replys150',\n",
       " 'intend',\n",
       " 'ldnw15h',\n",
       " '69696',\n",
       " 'laundry',\n",
       " 'newscaster',\n",
       " 'hmv1',\n",
       " '2006',\n",
       " 'minor',\n",
       " 'jobyet',\n",
       " '930',\n",
       " 'speciale',\n",
       " 'lotsof',\n",
       " 'reality',\n",
       " 'tc',\n",
       " 'tmorow',\n",
       " 'becomes',\n",
       " '3mobile',\n",
       " 'quizclub',\n",
       " 'consider',\n",
       " 'xxxxxxx',\n",
       " 'youdoing',\n",
       " 'uttered',\n",
       " 'whoever',\n",
       " 'ttyl',\n",
       " 'imagination',\n",
       " 'possessiveness',\n",
       " 'iphone',\n",
       " 'owned',\n",
       " 'real1',\n",
       " '99',\n",
       " 'law',\n",
       " 'liver',\n",
       " 'eastenders',\n",
       " 'carolina',\n",
       " 'manual',\n",
       " 'aha',\n",
       " 'tyrone',\n",
       " 'ten',\n",
       " '450',\n",
       " '4xx26',\n",
       " 'writhing',\n",
       " 'wk',\n",
       " 'questioned',\n",
       " 'star',\n",
       " 'your',\n",
       " 'opened',\n",
       " 'offline',\n",
       " 'billy',\n",
       " 'deal',\n",
       " 'card',\n",
       " 'wthout',\n",
       " 'colany',\n",
       " 'doors',\n",
       " 'inshah',\n",
       " 'repent',\n",
       " 'nature',\n",
       " 'kid',\n",
       " 'piss',\n",
       " 'organise',\n",
       " 'continued',\n",
       " 'weather',\n",
       " 'checked',\n",
       " 'avent',\n",
       " 'colleg',\n",
       " '150',\n",
       " 'lark',\n",
       " 'wnt',\n",
       " 'braindance',\n",
       " 'hmmross',\n",
       " 'willing',\n",
       " 'dismay',\n",
       " 'voila',\n",
       " 'game',\n",
       " '3aj',\n",
       " '02',\n",
       " 'steve',\n",
       " '7ws',\n",
       " 'wherever',\n",
       " 'irritated',\n",
       " 'claire',\n",
       " 'sorry',\n",
       " 'source',\n",
       " 'mylife',\n",
       " 'glands',\n",
       " 'rstm',\n",
       " 'cab',\n",
       " 'stuffing',\n",
       " 'dog',\n",
       " 'lttrs',\n",
       " 'gone',\n",
       " 'current',\n",
       " 'tb',\n",
       " 'crisis',\n",
       " 'jones',\n",
       " 'previously',\n",
       " 'start',\n",
       " 'cam',\n",
       " 'half',\n",
       " 'joke',\n",
       " 'threw',\n",
       " 'atten',\n",
       " 'cards',\n",
       " 'overdose',\n",
       " 'id',\n",
       " 'l',\n",
       " 'algebra',\n",
       " 'loyalty',\n",
       " 'difficult',\n",
       " 'salam',\n",
       " 'petticoatdreams',\n",
       " 'dogwood',\n",
       " 'wanted',\n",
       " 'digital',\n",
       " 'locations',\n",
       " 'favour',\n",
       " 'lowes',\n",
       " 'guess',\n",
       " 'situation',\n",
       " 'cultures',\n",
       " 'minmobsmorelkpobox177hp51fl',\n",
       " 'nytho',\n",
       " 'edward',\n",
       " 'coming',\n",
       " 'diamonds',\n",
       " 'mus',\n",
       " 'terry',\n",
       " 'goigng',\n",
       " 'active',\n",
       " '08000938767',\n",
       " 'satsgettin',\n",
       " 'smiling',\n",
       " 'workage',\n",
       " 'score',\n",
       " 'character',\n",
       " '150pm',\n",
       " 'crying',\n",
       " 'hopeso',\n",
       " '07099833605',\n",
       " 'lodge',\n",
       " 'hearing',\n",
       " 'unintentionally',\n",
       " '2marrow',\n",
       " 'matched',\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to create a table of frequency of each word per SMS \n",
    "\n",
    "word_freq_per_sms = {word: [0] * len(train_data['SMS']) for word in vocab}\n",
    "\n",
    "for i, sms in enumerate(train_data['SMS']):\n",
    "    for word in sms:\n",
    "        word_freq_per_sms[word][i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>0870753331018</th>\n",
       "      <th>priority</th>\n",
       "      <th>nokia</th>\n",
       "      <th>xy</th>\n",
       "      <th>89693</th>\n",
       "      <th>bid</th>\n",
       "      <th>300</th>\n",
       "      <th>lover</th>\n",
       "      <th>rcd</th>\n",
       "      <th>...</th>\n",
       "      <th>blocked</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>argue</th>\n",
       "      <th>curious</th>\n",
       "      <th>latr</th>\n",
       "      <th>juliana</th>\n",
       "      <th>pobox202</th>\n",
       "      <th>poortiyagi</th>\n",
       "      <th>dough</th>\n",
       "      <th>gving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   true  0870753331018  priority  nokia  xy  89693  bid  300  lover  rcd  ...  \\\n",
       "0     0              0         0      0   0      0    0    0      0    0  ...   \n",
       "1     0              0         0      0   0      0    0    0      0    0  ...   \n",
       "2     0              0         0      0   0      0    0    0      0    0  ...   \n",
       "3     0              0         0      0   0      0    0    0      0    0  ...   \n",
       "4     0              0         0      0   0      0    0    0      0    0  ...   \n",
       "\n",
       "   blocked  vomiting  argue  curious  latr  juliana  pobox202  poortiyagi  \\\n",
       "0        0         0      0        0     0        0         0           0   \n",
       "1        0         0      0        0     0        0         0           0   \n",
       "2        0         0      0        0     0        0         0           0   \n",
       "3        0         0      0        0     0        0         0           0   \n",
       "4        0         0      0        0     0        0         0           0   \n",
       "\n",
       "   dough  gving  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 7212 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = pd.DataFrame(word_freq_per_sms)\n",
    "word_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>true</th>\n",
       "      <th>0870753331018</th>\n",
       "      <th>priority</th>\n",
       "      <th>nokia</th>\n",
       "      <th>xy</th>\n",
       "      <th>89693</th>\n",
       "      <th>bid</th>\n",
       "      <th>300</th>\n",
       "      <th>...</th>\n",
       "      <th>blocked</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>argue</th>\n",
       "      <th>curious</th>\n",
       "      <th>latr</th>\n",
       "      <th>juliana</th>\n",
       "      <th>pobox202</th>\n",
       "      <th>poortiyagi</th>\n",
       "      <th>dough</th>\n",
       "      <th>gving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  true  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]     0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...     0   \n",
       "2   ham                    [welp, apparently, he, retired]     0   \n",
       "3   ham                                           [havent]     0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...     0   \n",
       "\n",
       "   0870753331018  priority  nokia  xy  89693  bid  300  ...  blocked  \\\n",
       "0              0         0      0   0      0    0    0  ...        0   \n",
       "1              0         0      0   0      0    0    0  ...        0   \n",
       "2              0         0      0   0      0    0    0  ...        0   \n",
       "3              0         0      0   0      0    0    0  ...        0   \n",
       "4              0         0      0   0      0    0    0  ...        0   \n",
       "\n",
       "   vomiting  argue  curious  latr  juliana  pobox202  poortiyagi  dough  gving  \n",
       "0         0      0        0     0        0         0           0      0      0  \n",
       "1         0      0        0     0        0         0           0      0      0  \n",
       "2         0      0        0     0        0         0           0      0      0  \n",
       "3         0      0        0     0        0         0           0      0      0  \n",
       "4         0      0        0     0        0         0           0      0      0  \n",
       "\n",
       "[5 rows x 7214 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_cleaned = pd.concat([train_data, word_freq], axis=1)\n",
    "train_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to use multinomial naive bayes algorithm, need to calculate two probabilities:\n",
    "# P(spam | w1,w2,w3,....,wn) and P(ham | w1,w2,w3,....,wn)\n",
    "\n",
    "# first separating spam and ham messages \n",
    "spam_sms = train_data_cleaned[train_data_cleaned['Label'] == 'spam']\n",
    "ham_sms = train_data_cleaned[train_data_cleaned['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_sms) / len(train_data)\n",
    "p_ham = len(ham_sms) / len(train_data)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_sms = spam_sms['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_sms.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_sms = ham_sms['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_sms.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocab = len(vocab)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating parameters\n",
    "param_spam = {word:0 for word in vocab}\n",
    "param_ham = {word:0 for word in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating parameters\n",
    "for word in vocab:\n",
    "    n_word_given_spam = spam_sms[word].sum() # spam_messages already defined\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocab)\n",
    "    param_spam[word] = p_word_given_spam\n",
    "\n",
    "    n_word_given_ham = ham_sms[word].sum() # ham_messages already defined\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocab)\n",
    "    param_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to classify new messages \n",
    "import re\n",
    "\n",
    "def classification(sms):\n",
    "    sms = re.sub('\\W', ' ', sms)\n",
    "    sms = sms.lower().split()\n",
    "\n",
    "    p_spam_sms = p_spam\n",
    "    p_ham_sms = p_ham\n",
    "\n",
    "    for word in sms:\n",
    "        if word in param_spam:\n",
    "            p_spam_sms *= param_spam[word]\n",
    "\n",
    "        if word in param_ham: \n",
    "            p_ham_sms *= param_ham[word]\n",
    "\n",
    "    print('P(Spam|sms):', p_spam_sms)\n",
    "    print('P(Ham|sms):', p_ham_sms)\n",
    "\n",
    "    if p_ham_sms > p_spam_sms:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_sms < p_spam_sms:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|sms): 5.904203202197771e-26\n",
      "P(Ham|sms): 2.9520580445641527e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classification('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|sms): 2.1098884398714407e-25\n",
      "P(Ham|sms): 4.453247150467117e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classification(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to test classification of naive bayes\n",
    "\n",
    "def test_classification(sms):\n",
    "    sms = re.sub('\\W', ' ', sms)\n",
    "    sms = sms.lower().split()\n",
    "\n",
    "    p_spam_sms = p_spam\n",
    "    p_ham_sms = p_ham\n",
    "\n",
    "    for word in sms:\n",
    "        if word in param_spam:\n",
    "            p_spam_sms *= param_spam[word]\n",
    "\n",
    "        if word in param_ham: \n",
    "            p_ham_sms *= param_ham[word]\n",
    "\n",
    "    if p_ham_sms > p_spam_sms:\n",
    "        return 'ham'\n",
    "    elif p_ham_sms < p_spam_sms:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'undetermined'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Camera quite good, 10.1mega pixels, 3optical a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>At 4. Let's go to bill millers</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is there coming friday is leave for pongal?do ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER! As a valued network customer you hvae ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yar... I tot u knew dis would happen long ago ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  Camera quite good, 10.1mega pixels, 3optical a...       ham\n",
       "1   ham                     At 4. Let's go to bill millers       ham\n",
       "2   ham  Is there coming friday is leave for pongal?do ...       ham\n",
       "3  spam  WINNER! As a valued network customer you hvae ...      spam\n",
       "4   ham  Yar... I tot u knew dis would happen long ago ...       ham"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['predicted'] = test_data['SMS'].apply(test_classification)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986244019138756\n"
     ]
    }
   ],
   "source": [
    "#Evaluate classification function \n",
    "# by calculating accuracy ( acc = correctly classified / total classfied)\n",
    "\n",
    "correct = 0 \n",
    "total = test_data.shape[0]\n",
    "\n",
    "for row in test_data.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print('Accuracy:', correct/total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achieved an accuracy of 98.6 % using multinomial naive bayes classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
